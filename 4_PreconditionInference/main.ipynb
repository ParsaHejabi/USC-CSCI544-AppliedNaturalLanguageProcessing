{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "PNTAD5CyeJk7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7evt3KkdiJX",
        "outputId": "5938f142-f745-47e4-f4fb-ff5ca5e01bbd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOCV9MIuayrJ"
      },
      "source": [
        "### Read training, dev and unlabeled test data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dXAizP-a4zA",
        "outputId": "ca467262-e28d-4cc5-d3c0-3f061c5b7ede"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_ADDRESS = '/content/drive/MyDrive/UniversityOfSouthernCalifornia/Term2-Spring2022/CSCI544-AppliedNLP/CodingAssignments/4_PreconditionInference/HW4_upload/data/'\n",
        "TRAIN_DATA_ADDRESS = '/content/drive/MyDrive/UniversityOfSouthernCalifornia/Term2-Spring2022/CSCI544-AppliedNLP/CodingAssignments/4_PreconditionInference/HW4_upload/data/pnli_train.csv'\n",
        "DEV_DATA_ADDRESS = '/content/drive/MyDrive/UniversityOfSouthernCalifornia/Term2-Spring2022/CSCI544-AppliedNLP/CodingAssignments/4_PreconditionInference/HW4_upload/data/pnli_dev.csv'\n",
        "TEST_DATA_ADDRESS = '/content/drive/MyDrive/UniversityOfSouthernCalifornia/Term2-Spring2022/CSCI544-AppliedNLP/CodingAssignments/4_PreconditionInference/HW4_upload/data/pnli_test_unlabeled.csv'\n",
        "PREDICTION_ADDRESS = '/content/drive/MyDrive/UniversityOfSouthernCalifornia/Term2-Spring2022/CSCI544-AppliedNLP/CodingAssignments/4_PreconditionInference/HW4_upload/'"
      ],
      "metadata": {
        "id": "dB4TKJoZbWAi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpCjpuPQayrN"
      },
      "source": [
        "The following provides a starting code (Python 3) of how to read the labeled training and dev sentence pairs, and unlabeled test sentence pairs, into lists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fih_JUA9ayrO"
      },
      "outputs": [],
      "source": [
        "train, dev, test = [], [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4npuhABayrP",
        "outputId": "0a2fb246-3d13-49c4-c49f-b54288106320"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5983\n",
            "[['Sometimes do exercise.', 'A person typically desire healthy life.', '1'], ['Who eats junk foods.', 'A person typically desire healthy life.', '0'], ['A person is sick.', 'A person typically desire healthy life.', '1']]\n"
          ]
        }
      ],
      "source": [
        "with open(f'{DATA_ADDRESS}pnli_train.csv', encoding='utf-8') as fp:\n",
        "  csvreader = csv.reader(fp)\n",
        "  for x in csvreader:\n",
        "    # x[2] will be the label (0 or 1). x[0] and x[1] will be the sentence pairs.\n",
        "    train.append(x)\n",
        "print(len(train))\n",
        "print(train[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiVm5IlqayrQ",
        "outputId": "7ff61520-047e-49dd-826f-4df5de147de8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1055\n",
            "[['A person is looking for accuracy.', 'A person typically desires accurate results.', '1'], ['A person does not care for accuracy.', 'A person typically desires accurate results.', '0'], ['The person double checks their data.', 'A person typically desires accurate results.', '1']]\n"
          ]
        }
      ],
      "source": [
        "with open(f'{DATA_ADDRESS}pnli_dev.csv', encoding='utf-8') as fp:\n",
        "  csvreader = csv.reader(fp)\n",
        "  for x in csvreader:\n",
        "    # x[2] will be the label (0 or 1). x[0] and x[1] will be the sentence pairs.\n",
        "    dev.append(x)\n",
        "print(len(dev))\n",
        "print(dev[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cIXfdayayrR",
        "outputId": "75713d3d-3a0c-46b8-a7fa-ecca26232f58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4850\n",
            "[['The people want to have a romantic and pleasant feel.', 'People typically does desire to smell violets.'], ['The contract is to buy products from you.', 'Getting contract typically cause to make money or spend money.'], ['Train station is closed.', 'Line can typically be used to move train along tracks.']]\n"
          ]
        }
      ],
      "source": [
        "with open(f'{DATA_ADDRESS}pnli_test_unlabeled.csv', encoding='utf-8') as fp:\n",
        "  csvreader = csv.reader(fp)\n",
        "  for x in csvreader:\n",
        "    # x[0] and x[1] will be the sentence pairs.\n",
        "    test.append(x)\n",
        "print(len(test))\n",
        "print(test[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating PyTorch dataset and dataloader"
      ],
      "metadata": {
        "id": "bZkN1PDid_PG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ecm0HzD3FEy",
        "outputId": "af2d44a5-5a88-4d7d-db04-e42558fedb81"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import TensorDataset"
      ],
      "metadata": {
        "id": "wgrYe4DC2368"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
      ],
      "metadata": {
        "id": "GRp6BRhSPEgx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 8"
      ],
      "metadata": {
        "id": "ae6FrIHqjjro"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PITrainDevDataset(Dataset):\n",
        "  def __init__(self, data_dir, verbose=False):\n",
        "    self.preconditions = []\n",
        "    self.statements = []\n",
        "    self.labels = []\n",
        "\n",
        "    with open(data_dir, encoding='utf-8') as fp:\n",
        "      csvreader = csv.reader(fp)\n",
        "      for x in csvreader:\n",
        "        self.preconditions.append(x[0])\n",
        "        self.statements.append(x[1])\n",
        "        self.labels.append(int(x[2]))\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.preconditions)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return (self.preconditions[index], self.statements[index], self.labels[index])"
      ],
      "metadata": {
        "id": "wDvmI00CeV0j"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PITestDataset(Dataset):\n",
        "  def __init__(self, data_dir, verbose=False):\n",
        "    self.preconditions = []\n",
        "    self.statements = []\n",
        "\n",
        "    with open(data_dir, encoding='utf-8') as fp:\n",
        "      csvreader = csv.reader(fp)\n",
        "      for x in csvreader:\n",
        "        self.preconditions.append(x[0])\n",
        "        self.statements.append(x[1])\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.preconditions)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return (self.preconditions[index], self.statements[index])"
      ],
      "metadata": {
        "id": "dPp5N4QAAMza"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "  token_ids_list = []\n",
        "  mask_ids_list = []\n",
        "  segment_ids_list = []\n",
        "  labels_list = []\n",
        "\n",
        "  verbose = False\n",
        "\n",
        "  for index in range(len(batch)):\n",
        "    tokenized_precondition = tokenizer.encode(batch[index][0], add_special_tokens=False)\n",
        "    tokenized_statement = tokenizer.encode(batch[index][1], add_special_tokens=False)\n",
        "    tokenized_concatenated = [*[tokenizer.cls_token_id], *tokenized_precondition, *[tokenizer.sep_token_id], *tokenized_statement, *[tokenizer.sep_token_id]]\n",
        "    mask_ids = [1] * len(tokenized_concatenated)\n",
        "    segment_ids = [*([0] * (len(tokenized_precondition) + 2)), *([1] * (len(tokenized_statement) + 1))]\n",
        "\n",
        "    assert len(tokenized_concatenated) == len(tokenized_precondition) + len(tokenized_statement) + 3\n",
        "    assert len(mask_ids) == len(segment_ids) and len(mask_ids) == len(tokenized_concatenated)\n",
        "\n",
        "    if verbose == True:\n",
        "      print(f'Precondition: {batch[index][0]}')\n",
        "      print(f'Tokenized precondition: {tokenized_precondition}')\n",
        "      print(f'Statement: {batch[index][1]}')\n",
        "      print(f'Tokenized statement: {tokenized_statement}')\n",
        "      print(f'Tokenized concatenated: {tokenized_concatenated}')\n",
        "      print(f'Mask ids: {mask_ids}')\n",
        "      print(f'Segment ids: {segment_ids}')\n",
        "\n",
        "    tokenized_concatenated = torch.tensor(tokenized_concatenated)\n",
        "    mask_ids = torch.tensor(mask_ids)\n",
        "    segment_ids = torch.tensor(segment_ids)\n",
        "\n",
        "    token_ids_list.append(tokenized_concatenated)\n",
        "    mask_ids_list.append(mask_ids)\n",
        "    segment_ids_list.append(segment_ids)\n",
        "\n",
        "    labels_list.append(batch[index][2])\n",
        "\n",
        "  token_ids_list = pad_sequence(token_ids_list, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "  mask_ids_list = pad_sequence(mask_ids_list, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "  segment_ids_list = pad_sequence(segment_ids_list, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "  labels_list = torch.tensor(labels_list)\n",
        "\n",
        "  return token_ids_list, mask_ids_list, segment_ids_list, labels_list"
      ],
      "metadata": {
        "id": "U2efksz0OhSb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn_test(batch):\n",
        "  token_ids_list = []\n",
        "  mask_ids_list = []\n",
        "  segment_ids_list = []\n",
        "\n",
        "  verbose = False\n",
        "\n",
        "  for index in range(len(batch)):\n",
        "    tokenized_precondition = tokenizer.encode(batch[index][0], add_special_tokens=False)\n",
        "    tokenized_statement = tokenizer.encode(batch[index][1], add_special_tokens=False)\n",
        "    tokenized_concatenated = [*[tokenizer.cls_token_id], *tokenized_precondition, *[tokenizer.sep_token_id], *tokenized_statement, *[tokenizer.sep_token_id]]\n",
        "    mask_ids = [1] * len(tokenized_concatenated)\n",
        "    segment_ids = [*([0] * (len(tokenized_precondition) + 2)), *([1] * (len(tokenized_statement) + 1))]\n",
        "\n",
        "    assert len(tokenized_concatenated) == len(tokenized_precondition) + len(tokenized_statement) + 3\n",
        "    assert len(mask_ids) == len(segment_ids) and len(mask_ids) == len(tokenized_concatenated)\n",
        "\n",
        "    if verbose == True:\n",
        "      print(f'Precondition: {batch[index][0]}')\n",
        "      print(f'Tokenized precondition: {tokenized_precondition}')\n",
        "      print(f'Statement: {batch[index][1]}')\n",
        "      print(f'Tokenized statement: {tokenized_statement}')\n",
        "      print(f'Tokenized concatenated: {tokenized_concatenated}')\n",
        "      print(f'Mask ids: {mask_ids}')\n",
        "      print(f'Segment ids: {segment_ids}')\n",
        "\n",
        "    tokenized_concatenated = torch.tensor(tokenized_concatenated)\n",
        "    mask_ids = torch.tensor(mask_ids)\n",
        "    segment_ids = torch.tensor(segment_ids)\n",
        "\n",
        "    token_ids_list.append(tokenized_concatenated)\n",
        "    mask_ids_list.append(mask_ids)\n",
        "    segment_ids_list.append(segment_ids)\n",
        "\n",
        "  token_ids_list = pad_sequence(token_ids_list, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "  mask_ids_list = pad_sequence(mask_ids_list, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "  segment_ids_list = pad_sequence(segment_ids_list, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "\n",
        "  return token_ids_list, mask_ids_list, segment_ids_list"
      ],
      "metadata": {
        "id": "Wsnt-K9_AXH_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = PITrainDevDataset(TRAIN_DATA_ADDRESS)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "dev_dataset = PITrainDevDataset(DEV_DATA_ADDRESS)\n",
        "dev_dataloader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "test_dataset = PITestDataset(TEST_DATA_ADDRESS)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn_test)"
      ],
      "metadata": {
        "id": "CLZ55rlKjZUG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_token_ids_list, train_mask_ids_list, train_segment_ids_list, train_labels_list = next(iter(train_dataloader))\n",
        "print(f\"Token ids batch shape: {train_token_ids_list.size()}\")\n",
        "print(f\"Mask ids batch shape: {train_mask_ids_list.size()}\")\n",
        "print(f\"segment ids batch shape: {train_segment_ids_list.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels_list.size()}\")\n",
        "label = train_labels_list[0]\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zT13fCutjvNm",
        "outputId": "a45339a0-356e-48c2-bc0e-55b9c4db3810"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token ids batch shape: torch.Size([8, 22])\n",
            "Mask ids batch shape: torch.Size([8, 22])\n",
            "segment ids batch shape: torch.Size([8, 22])\n",
            "Labels batch shape: torch.Size([8])\n",
            "Label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = 1\n",
        "print(train_token_ids_list[index])\n",
        "print(train_mask_ids_list[index])\n",
        "print(train_segment_ids_list[index])\n",
        "print(train[index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZErKYXiBliGl",
        "outputId": "5456d757-5367-4258-8eb3-cd77762fdd38"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([    0, 12375, 24923, 15163,  6592,     4,     2,   250,   621,  3700,\n",
            "         4724,  2245,   301,     4,     2,     1,     1,     1,     1,     1,\n",
            "            1,     1])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "['Who eats junk foods.', 'A person typically desire healthy life.', '0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_token_ids_list, dev_mask_ids_list, dev_segment_ids_list, dev_labels_list = next(iter(dev_dataloader))\n",
        "print(f\"Token ids batch shape: {dev_token_ids_list.size()}\")\n",
        "print(f\"Mask ids batch shape: {dev_mask_ids_list.size()}\")\n",
        "print(f\"segment ids batch shape: {dev_segment_ids_list.size()}\")\n",
        "print(f\"Labels batch shape: {dev_labels_list.size()}\")\n",
        "label = dev_labels_list[0]\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCdSd6ZQf9Yf",
        "outputId": "9486b771-f816-4d03-e0ae-24b2f8fc6e38"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token ids batch shape: torch.Size([8, 19])\n",
            "Mask ids batch shape: torch.Size([8, 19])\n",
            "segment ids batch shape: torch.Size([8, 19])\n",
            "Labels batch shape: torch.Size([8])\n",
            "Label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZE5slL8ayrS"
      },
      "source": [
        "### Main Code Body"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkMAFrR7ayrS"
      },
      "source": [
        "You may choose to experiment with different methods using your program. However, you need to embed the training and inference processes at here. We will use your prediction on the unlabeled test data to grade, while checking this part to understand how your method has produced the predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load model"
      ],
      "metadata": {
        "id": "mgiNFnxzVGne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, get_scheduler\n",
        "from torch.optim import AdamW"
      ],
      "metadata": {
        "id": "siBBF50lVGIh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "7EDlb4Y87idr"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 1e-5\n",
        "EPOCHS = 20\n",
        "NUM_TRAINING_STEPS = EPOCHS * len(train_dataloader)"
      ],
      "metadata": {
        "id": "U7LasHKMVjsr"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "xJ6gsXOcVRh7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa7b5b4f-acd7-4589-b6b3-8f88ee7df30e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.roberta.config.type_vocab_size = 2\n",
        "single_emb = model.roberta.embeddings.token_type_embeddings\n",
        "model.roberta.embeddings.token_type_embeddings = torch.nn.Embedding(2, single_emb.embedding_dim)\n",
        "model.roberta.embeddings.token_type_embeddings.weight = torch.nn.Parameter(single_emb.weight.repeat([2, 1]))"
      ],
      "metadata": {
        "id": "UaRLWxB_nfGS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "78fkoG9b3gcI"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=NUM_TRAINING_STEPS\n",
        ")"
      ],
      "metadata": {
        "id": "nBz7qU0u4nCJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train"
      ],
      "metadata": {
        "id": "xTW8ZuES0k1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "progress_bar = tqdm(range(NUM_TRAINING_STEPS))\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "  model.train()\n",
        "  total_train_loss = 0\n",
        "  total_train_acc  = 0\n",
        "  for batch_idx, (train_token_ids_list, train_mask_ids_list, train_segment_ids_list, train_labels_list) in enumerate(train_dataloader):\n",
        "    optimizer.zero_grad()\n",
        "    train_token_ids_list = train_token_ids_list.to(device)\n",
        "    train_mask_ids_list = train_mask_ids_list.to(device)\n",
        "    train_segment_ids_list = train_segment_ids_list.to(device)\n",
        "    train_labels_list = train_labels_list.to(device)\n",
        "    # print(train_token_ids_list)\n",
        "    # print(train_mask_ids_list)\n",
        "    # print(train_segment_ids_list)\n",
        "    # print(train_labels_list)\n",
        "\n",
        "    prediction = model(input_ids=train_token_ids_list,\n",
        "                       token_type_ids=train_segment_ids_list,\n",
        "                       attention_mask=train_mask_ids_list,\n",
        "                       labels=train_labels_list)\n",
        "    \n",
        "    # print(f'Prediction: {prediction}')\n",
        "    \n",
        "    loss = prediction.loss\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    lr_scheduler.step()\n",
        "    progress_bar.update(1)\n",
        "\n",
        "    # print(torch.log_softmax(prediction.logits, dim=1))\n",
        "    # print(torch.log_softmax(prediction.logits, dim=1).argmax(dim=1))\n",
        "    # print(f'train_labels_list: {train_labels_list}')\n",
        "    # print((torch.log_softmax(prediction.logits, dim=1).argmax(dim=1) == train_labels_list).sum().float() / float(BATCH_SIZE))\n",
        "    \n",
        "    total_train_loss += loss.item()\n",
        "    total_train_acc  += ((torch.log_softmax(prediction.logits, dim=1).argmax(dim=1) == train_labels_list).sum().float() / float(BATCH_SIZE)).item()\n",
        "\n",
        "  train_acc  = total_train_acc/len(train_dataloader)\n",
        "  train_loss = total_train_loss/len(train_dataloader)\n",
        "\n",
        "  model.eval()\n",
        "  total_val_acc  = 0\n",
        "  total_val_loss = 0\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, (dev_token_ids_list, dev_mask_ids_list, dev_segment_ids_list, dev_labels_list) in enumerate(dev_dataloader):\n",
        "      dev_token_ids_list = dev_token_ids_list.to(device)\n",
        "      dev_mask_ids_list = dev_mask_ids_list.to(device)\n",
        "      dev_segment_ids_list = dev_segment_ids_list.to(device)\n",
        "      dev_labels_list = dev_labels_list.to(device)\n",
        "\n",
        "      prediction = model(dev_token_ids_list, token_type_ids=dev_segment_ids_list,\n",
        "                               attention_mask=dev_mask_ids_list,\n",
        "                               labels=dev_labels_list)\n",
        "      \n",
        "      loss = prediction.loss\n",
        "\n",
        "      total_val_loss += loss.item()\n",
        "      total_val_acc  += ((torch.log_softmax(prediction.logits, dim=1).argmax(dim=1) == dev_labels_list).sum().float() / float(BATCH_SIZE)).item()\n",
        "\n",
        "  val_acc  = total_val_acc/len(dev_dataloader)\n",
        "  val_loss = total_val_loss/len(dev_dataloader)\n",
        "\n",
        "  print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438,
          "referenced_widgets": [
            "f80dba8bcc244261a15d865a364dd1cd",
            "600097daf36d4e1e8257f946bbb3a191",
            "c219a37754c54eeab05cc597733b5557",
            "207b4c942ad645c99bbccfc322353390",
            "f49f02d5f3524c14a45720b82c1d7188",
            "c0ab29e7510749bf954eb8cd82a6f4c8",
            "3b2d58cf4bd74d93b72bc0520e66be6b",
            "c36d3a888f464b569282221916d8fc13",
            "f15c071577de4e248510c21bb93b98ce",
            "7daec8e1f4b64a1ca9acb8cb7119c657",
            "fbbfcce9df274ad6a86ce838111d5825",
            "2d83737f4d444bebbe217a99b28e2fcb",
            "5eb94bfb5fc74666b60d8add2e569fc5",
            "2cb0dac845484532a2ec82779497b6c2",
            "781ad8f7d3994a9492004432b8a54601",
            "8e05ccaa9f764a8e9f450664c3855207",
            "3daf6176fd37444fb7736d1e0fad3ac6",
            "c5455b923df54814beaa6ecfe48e6956",
            "31c3ed03b5dc47eb8fe77caabdf84a35",
            "2cba6dcbf5164fbba71fe6080e739b5e",
            "7d017a318932403db028261c136e9876",
            "61d0c7e717d64ac4be5073135efb38ea"
          ]
        },
        "id": "CIPtm_bVfJ5Z",
        "outputId": "66defb2a-bc4e-41c5-aacd-8039d2909d26"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/14960 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f80dba8bcc244261a15d865a364dd1cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d83737f4d444bebbe217a99b28e2fcb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train_loss: 0.4762 train_acc: 0.7569 | val_loss: 0.3520 val_acc: 0.8419\n",
            "Epoch 2: train_loss: 0.3102 train_acc: 0.8720 | val_loss: 0.3282 val_acc: 0.8712\n",
            "Epoch 3: train_loss: 0.2286 train_acc: 0.9116 | val_loss: 0.3592 val_acc: 0.8741\n",
            "Epoch 4: train_loss: 0.1777 train_acc: 0.9327 | val_loss: 0.3981 val_acc: 0.8807\n",
            "Epoch 5: train_loss: 0.1321 train_acc: 0.9512 | val_loss: 0.4451 val_acc: 0.8646\n",
            "Epoch 6: train_loss: 0.1078 train_acc: 0.9631 | val_loss: 0.4325 val_acc: 0.8845\n",
            "Epoch 7: train_loss: 0.0797 train_acc: 0.9748 | val_loss: 0.4548 val_acc: 0.8826\n",
            "Epoch 8: train_loss: 0.0644 train_acc: 0.9803 | val_loss: 0.4266 val_acc: 0.8750\n",
            "Epoch 9: train_loss: 0.0574 train_acc: 0.9820 | val_loss: 0.4296 val_acc: 0.8864\n",
            "Epoch 10: train_loss: 0.0439 train_acc: 0.9836 | val_loss: 0.5221 val_acc: 0.8911\n",
            "Epoch 11: train_loss: 0.0357 train_acc: 0.9898 | val_loss: 0.5081 val_acc: 0.8845\n",
            "Epoch 12: train_loss: 0.0314 train_acc: 0.9906 | val_loss: 0.5226 val_acc: 0.8873\n",
            "Epoch 13: train_loss: 0.0248 train_acc: 0.9921 | val_loss: 0.5472 val_acc: 0.8911\n",
            "Epoch 14: train_loss: 0.0173 train_acc: 0.9935 | val_loss: 0.5568 val_acc: 0.8845\n",
            "Epoch 15: train_loss: 0.0142 train_acc: 0.9948 | val_loss: 0.5924 val_acc: 0.8883\n",
            "Epoch 16: train_loss: 0.0171 train_acc: 0.9940 | val_loss: 0.6148 val_acc: 0.8939\n",
            "Epoch 17: train_loss: 0.0142 train_acc: 0.9947 | val_loss: 0.6263 val_acc: 0.8835\n",
            "Epoch 18: train_loss: 0.0083 train_acc: 0.9960 | val_loss: 0.6388 val_acc: 0.8873\n",
            "Epoch 19: train_loss: 0.0097 train_acc: 0.9957 | val_loss: 0.6459 val_acc: 0.8892\n",
            "Epoch 20: train_loss: 0.0100 train_acc: 0.9960 | val_loss: 0.6536 val_acc: 0.8902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eventually, results need to be a list of 2028 0 or 1's\n",
        "results = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for batch_idx, (test_token_ids_list, test_mask_ids_list, test_segment_ids_list) in enumerate(test_dataloader):\n",
        "    test_token_ids_list = test_token_ids_list.to(device)\n",
        "    test_mask_ids_list = test_mask_ids_list.to(device)\n",
        "    test_segment_ids_list = test_segment_ids_list.to(device)\n",
        "\n",
        "    prediction = model(test_token_ids_list,\n",
        "                       token_type_ids=test_segment_ids_list,\n",
        "                       attention_mask=test_mask_ids_list)\n",
        "\n",
        "    logits = prediction.logits\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "    results = results + predictions.tolist()\n",
        "    \n",
        "    # print(f'Prediction: {prediction}')\n",
        "    # print(f'Final Predictions: {predictions}')\n",
        "    # print(f'Results list: {results}')"
      ],
      "metadata": {
        "id": "gv7M0s0OA59g"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKWBSvi5ayrU"
      },
      "source": [
        "### Output Prediction Result File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkFpT2PFayrU"
      },
      "source": [
        "You will need to submit a prediction result file. It should have 2028 lines, every line should be either 0 or 1, which is your model's prediction on the respective test set instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "7ighzA7payrU"
      },
      "outputs": [],
      "source": [
        "# suppose you had your model's predictions on the 2028 test cases read from test_enc_unlabeled.tsv, and \n",
        "#those results are in the list called 'results'\n",
        "assert (len(results) == 4850)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "CGwo8oQ_ayrV"
      },
      "outputs": [],
      "source": [
        "# make sure the results are not float numbers, but intergers 0 and 1\n",
        "results = [int(x) for x in results]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "7QBh5HraayrV"
      },
      "outputs": [],
      "source": [
        "# write your prediction results to 'upload_predictions.txt' and upload that later\n",
        "with open(f'{PREDICTION_ADDRESS}upload_predictions_2_89_02.txt', 'w', encoding = 'utf-8') as fp:\n",
        "  for x in results:\n",
        "    fp.write(str(x) + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9HsQdwzREJpx"
      },
      "execution_count": 32,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "CSCI544-Assignment4-RoBERTa.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f80dba8bcc244261a15d865a364dd1cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_600097daf36d4e1e8257f946bbb3a191",
              "IPY_MODEL_c219a37754c54eeab05cc597733b5557",
              "IPY_MODEL_207b4c942ad645c99bbccfc322353390"
            ],
            "layout": "IPY_MODEL_f49f02d5f3524c14a45720b82c1d7188"
          }
        },
        "600097daf36d4e1e8257f946bbb3a191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0ab29e7510749bf954eb8cd82a6f4c8",
            "placeholder": "",
            "style": "IPY_MODEL_3b2d58cf4bd74d93b72bc0520e66be6b",
            "value": "100%"
          }
        },
        "c219a37754c54eeab05cc597733b5557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c36d3a888f464b569282221916d8fc13",
            "max": 14960,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f15c071577de4e248510c21bb93b98ce",
            "value": 14960
          }
        },
        "207b4c942ad645c99bbccfc322353390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7daec8e1f4b64a1ca9acb8cb7119c657",
            "placeholder": "",
            "style": "IPY_MODEL_fbbfcce9df274ad6a86ce838111d5825",
            "value": " 14960/14960 [23:20&lt;00:00, 11.24it/s]"
          }
        },
        "f49f02d5f3524c14a45720b82c1d7188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0ab29e7510749bf954eb8cd82a6f4c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b2d58cf4bd74d93b72bc0520e66be6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c36d3a888f464b569282221916d8fc13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f15c071577de4e248510c21bb93b98ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7daec8e1f4b64a1ca9acb8cb7119c657": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbbfcce9df274ad6a86ce838111d5825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d83737f4d444bebbe217a99b28e2fcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5eb94bfb5fc74666b60d8add2e569fc5",
              "IPY_MODEL_2cb0dac845484532a2ec82779497b6c2",
              "IPY_MODEL_781ad8f7d3994a9492004432b8a54601"
            ],
            "layout": "IPY_MODEL_8e05ccaa9f764a8e9f450664c3855207"
          }
        },
        "5eb94bfb5fc74666b60d8add2e569fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3daf6176fd37444fb7736d1e0fad3ac6",
            "placeholder": "",
            "style": "IPY_MODEL_c5455b923df54814beaa6ecfe48e6956",
            "value": "100%"
          }
        },
        "2cb0dac845484532a2ec82779497b6c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31c3ed03b5dc47eb8fe77caabdf84a35",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2cba6dcbf5164fbba71fe6080e739b5e",
            "value": 20
          }
        },
        "781ad8f7d3994a9492004432b8a54601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d017a318932403db028261c136e9876",
            "placeholder": "",
            "style": "IPY_MODEL_61d0c7e717d64ac4be5073135efb38ea",
            "value": " 20/20 [23:11&lt;00:00, 69.56s/it]"
          }
        },
        "8e05ccaa9f764a8e9f450664c3855207": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3daf6176fd37444fb7736d1e0fad3ac6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5455b923df54814beaa6ecfe48e6956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31c3ed03b5dc47eb8fe77caabdf84a35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cba6dcbf5164fbba71fe6080e739b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d017a318932403db028261c136e9876": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61d0c7e717d64ac4be5073135efb38ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}